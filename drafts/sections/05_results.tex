\chapter{Results}

This chapter presents the experimental results, including classification performance, confusion matrix analysis, statistical significance testing, feature importance analysis, error analysis, and comparison between speech tasks.

\section{Classification Performance}

\subsection{Overall Results}

Table \ref{tab:classification-results} summarises the classification performance for both speech tasks using 5-fold stratified cross-validation.

\begin{table}[h]
\centering
\caption{Classification results by task and algorithm}
\label{tab:classification-results}
\begin{tabular}{lcccc}
\hline
\textbf{Task} & \textbf{Algorithm} & \textbf{Accuracy} & \textbf{F1 Score} \\
\hline
Reading & SVM & 71.5\% $\pm$ 6.8\% & 0.73 \\
Reading & Random Forest & 72.3\% $\pm$ 7.2\% & 0.74 \\
\hline
Interview & SVM & 82.0\% $\pm$ 5.2\% & 0.85 \\
Interview & Random Forest & \textbf{87.1\%} $\pm$ 4.8\% & \textbf{0.88} \\
\hline
\end{tabular}
\end{table}

\subsubsection{Key Finding: Interview Outperforms Reading}

The most striking result is the substantial performance difference between tasks. Interview speech yields approximately 15 percentage points higher accuracy than reading speech across both classifiers:

\begin{itemize}
    \item \textbf{Reading task:} 71.5--72.3\% accuracy
    \item \textbf{Interview task:} 82.0--87.1\% accuracy
\end{itemize}

This suggests that spontaneous speech contains richer markers of depression than controlled reading, likely because it captures a broader range of cognitive and emotional processes.

\subsubsection{Classifier Comparison}

Random Forest marginally outperformed SVM on both tasks:
\begin{itemize}
    \item Reading: RF 72.3\% vs SVM 71.5\% (+0.8\%)
    \item Interview: RF 87.1\% vs SVM 82.0\% (+5.1\%)
\end{itemize}

The larger advantage on interview data may reflect Random Forest's ability to capture more complex feature interactions present in naturalistic speech.

\subsection{Statistical Significance}

To confirm that the performance difference between tasks is genuine and not due to random variation, a two-proportion z-test was conducted comparing the accuracy rates.

\begin{table}[h]
\centering
\caption{Statistical significance test: Reading vs Interview}
\label{tab:significance}
\begin{tabular}{lc}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Reading accuracy & 72.3\% \\
Interview accuracy & 87.1\% \\
Difference & 14.8\% \\
Z-statistic & 2.774 \\
P-value & 0.0055 \\
\hline
\end{tabular}
\end{table}

The p-value of 0.0055 is well below the conventional significance threshold of 0.05, indicating that \textbf{interview speech is statistically significantly better than reading speech for depression detection}. This result provides strong evidence that the observed difference reflects a genuine phenomenon rather than sampling variability.

\subsection{Confusion Matrix Analysis}

Confusion matrices provide detailed insight into classification errors. Tables \ref{tab:cm-reading} and \ref{tab:cm-interview} show the confusion matrices for Random Forest on each task.

\begin{table}[h]
\centering
\caption{Confusion matrix: Reading task (Random Forest)}
\label{tab:cm-reading}
\begin{tabular}{lcc}
\hline
 & \textbf{Predicted HC} & \textbf{Predicted PT} \\
\hline
\textbf{Actual HC} & 36 & 18 \\
\textbf{Actual PT} & 13 & 45 \\
\hline
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Confusion matrix: Interview task (Random Forest)}
\label{tab:cm-interview}
\begin{tabular}{lcc}
\hline
 & \textbf{Predicted HC} & \textbf{Predicted PT} \\
\hline
\textbf{Actual HC} & 44 & 8 \\
\textbf{Actual PT} & 7 & 57 \\
\hline
\end{tabular}
\end{table}

Key observations:

\paragraph{Reading Task:}
\begin{itemize}
    \item False Positives (HC $\rightarrow$ PT): 18 (33\% of healthy controls)
    \item False Negatives (PT $\rightarrow$ HC): 13 (22\% of patients)
    \item The model shows a slight bias toward predicting depression
\end{itemize}

\paragraph{Interview Task:}
\begin{itemize}
    \item False Positives: 8 (15\% of healthy controls)
    \item False Negatives: 7 (11\% of patients)
    \item Errors are more balanced and substantially fewer overall
\end{itemize}

The interview task's confusion matrix demonstrates not only higher accuracy but also more balanced error types, which is clinically important—both false positives (unnecessary worry) and false negatives (missed cases) are minimised.

\subsection{Detailed Classification Metrics}

Table \ref{tab:detailed-metrics} presents precision, recall, and F1 scores for each class.

\begin{table}[h]
\centering
\caption{Detailed classification metrics (Random Forest)}
\label{tab:detailed-metrics}
\begin{tabular}{llccc}
\hline
\textbf{Task} & \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
\hline
Reading & Healthy & 0.73 & 0.67 & 0.70 \\
Reading & Depressed & 0.71 & 0.78 & 0.74 \\
\hline
Interview & Healthy & 0.86 & 0.85 & 0.85 \\
Interview & Depressed & 0.88 & 0.89 & 0.88 \\
\hline
\end{tabular}
\end{table}

The interview task achieves substantially higher precision and recall for both classes, with particularly notable improvement in identifying healthy controls (recall increases from 67\% to 85\%).

\subsection{Comparison with Literature}

These results compare favourably with published work on the ANDROIDS corpus and similar datasets. Previous studies using comparable methods report accuracies ranging from 65--85\% depending on task and methodology. The 87.1\% accuracy achieved here on interview speech places this approach among the better-performing methods, while maintaining full interpretability through traditional machine learning.

\section{Feature Importance Analysis}

The primary research question concerns which acoustic features are most predictive of depression. This section presents feature importance results for both tasks.

\subsection{Reading Task Features}

Table \ref{tab:reading-features} shows the top 10 features for the reading task, ranked by Gini importance from the Random Forest classifier.

\begin{table}[h]
\centering
\caption{Top 10 predictive features for reading task}
\label{tab:reading-features}
\begin{tabular}{clc}
\hline
\textbf{Rank} & \textbf{Feature} & \textbf{Importance} \\
\hline
1 & slopeUV0-500\_amean & 0.050 \\
2 & mfcc1\_amean & 0.042 \\
3 & mfcc1\_stddevNorm & 0.041 \\
4 & loudnessPeaksPerSec & 0.036 \\
5 & StddevVoicedSegmentLengthSec & 0.032 \\
6 & mfcc1V\_amean & 0.029 \\
7 & slopeV500-1500\_stddevNorm & 0.027 \\
8 & VoicedSegmentsPerSec & 0.026 \\
9 & slopeV500-1500\_amean & 0.025 \\
10 & F2amplitudeLogRelF0\_amean & 0.025 \\
\hline
\end{tabular}
\end{table}

\subsubsection{Interpretation: Reading Task}

The reading task is dominated by:

\paragraph{Spectral Slope Features} The top-ranked feature (slopeUV0-500) measures the spectral tilt in unvoiced speech segments (0--500 Hz). Spectral slope reflects the relative energy distribution across frequencies, with flatter slopes indicating breathier or less energetic voice quality. This is consistent with the reduced vocal effort often observed in depression.

\paragraph{MFCC1 (First Mel-Frequency Cepstral Coefficient)} MFCC1 captures the overall spectral envelope shape, particularly energy distribution. Both the mean and variability of MFCC1 appear in the top 10, suggesting that depressed speech shows altered spectral characteristics.

\paragraph{Temporal Features} Loudness peaks per second and voiced segment variability indicate rhythm and prosodic differences. Depressed speech often exhibits reduced prosodic variation and altered speech timing.

\subsection{Interview Task Features}

Table \ref{tab:interview-features} shows the top 10 features for the interview task.

\begin{table}[h]
\centering
\caption{Top 10 predictive features for interview task}
\label{tab:interview-features}
\begin{tabular}{clc}
\hline
\textbf{Rank} & \textbf{Feature} & \textbf{Importance} \\
\hline
1 & spectralFluxV\_stddevNorm & 0.069 \\
2 & hammarbergIndexV\_stddevNorm & 0.043 \\
3 & StddevUnvoicedSegmentLength & 0.038 \\
4 & MeanUnvoicedSegmentLength & 0.035 \\
5 & alphaRatioV\_stddevNorm & 0.035 \\
6 & mfcc1V\_amean & 0.033 \\
7 & mfcc1V\_stddevNorm & 0.032 \\
8 & loudness\_stddevRisingSlope & 0.030 \\
9 & loudness\_stddevFallingSlope & 0.026 \\
10 & logRelF0-H1-A3\_amean & 0.020 \\
\hline
\end{tabular}
\end{table}

\subsubsection{Interpretation: Interview Task}

The interview task shows a distinctly different feature profile:

\paragraph{Spectral Flux Variability} The most important feature is the variability of spectral flux in voiced regions. Spectral flux measures frame-to-frame spectral change, and its variability reflects dynamic speech modulation. Reduced variability may indicate the monotonous speech characteristic of depression.

\paragraph{Voice Quality Measures} The Hammarberg index and alpha ratio both appear prominently. These measure the balance between low and high frequency energy, reflecting voice quality characteristics like breathiness and vocal strain. The importance of their \textit{variability} suggests that dynamic changes in voice quality during speech are particularly informative.

\paragraph{Pausing Behaviour} Both the mean and variability of unvoiced segment length feature prominently. Unvoiced segments correspond to pauses and hesitations. This is clinically meaningful: depression is associated with psychomotor retardation and altered speech timing, manifesting as longer and more variable pauses.

\paragraph{Loudness Dynamics} The variability of loudness slopes (both rising and falling) indicates prosodic expression. Reduced loudness modulation is a recognised marker of flat affect in depression.

\section{Task Comparison}

\subsection{Feature Overlap}

Comparing the top 10 features between tasks reveals limited overlap:

\begin{itemize}
    \item \textbf{Shared features:} mfcc1V (both mean and variability)
    \item \textbf{Overlap:} Only 2-3 features appear in both top-10 lists
\end{itemize}

This suggests that different acoustic markers are salient depending on speech context.

\subsection{Feature Categories by Task}

Table \ref{tab:feature-categories-comparison} categorises the dominant features for each task.

\begin{table}[h]
\centering
\caption{Dominant feature categories by task}
\label{tab:feature-categories-comparison}
\begin{tabular}{lll}
\hline
\textbf{Category} & \textbf{Reading} & \textbf{Interview} \\
\hline
Spectral & Slope, MFCC1 & Flux, MFCC1V \\
Voice Quality & -- & Hammarberg, Alpha ratio \\
Temporal & Voiced segments & Unvoiced segments (pauses) \\
Prosodic & Loudness peaks & Loudness dynamics \\
\hline
\end{tabular}
\end{table}

\subsection{Clinical Interpretation}

The task-specific feature profiles suggest different cognitive mechanisms are captured:

\paragraph{Reading Task} Reading a scripted text primarily reveals \textit{voice production} characteristics (spectral slope, MFCC) and basic rhythm (loudness peaks). These may reflect the physiological and motor aspects of depression.

\paragraph{Interview Task} Spontaneous speech reveals \textit{cognitive and affective} processes: variable pausing (cognitive load, word-finding), reduced vocal dynamics (flat affect), and voice quality changes (emotional expression). The interview task places greater demands on executive function, emotional regulation, and language production—all of which are impacted by depression.

This explains the superior classification performance on interview speech: it captures a broader range of depression-related processes.

\section{Error Analysis}

Understanding which samples are misclassified provides insight into model limitations and potential confounding factors.

\subsection{Misclassification Patterns}

Analysis of misclassified samples revealed a notable pattern related to gender:

\begin{table}[h]
\centering
\caption{Misclassification by gender}
\label{tab:error-gender}
\begin{tabular}{lcc}
\hline
\textbf{Task} & \textbf{Female Errors} & \textbf{Male Errors} \\
\hline
Reading & 23 & 8 \\
Interview & 12 & 3 \\
\hline
\end{tabular}
\end{table}

Female speakers were more frequently misclassified in both tasks. This could reflect:

\begin{enumerate}
    \item \textbf{Sample imbalance:} Potential over-representation of one gender in the dataset
    \item \textbf{Feature bias:} Acoustic features may capture depression differently across genders
    \item \textbf{Expression differences:} Gender differences in how depression manifests in speech
\end{enumerate}

This finding suggests that future work should consider gender-specific models or features, and highlights a limitation of the current approach.

\subsection{Age Patterns}

The mean age of misclassified samples (47.9 years for reading task) was similar to the overall dataset mean, suggesting age was not a significant confounding factor in classification errors.

\section{Learning Curve Analysis}

Learning curves assess whether the model would benefit from additional training data and whether overfitting is occurring.

Figure \ref{fig:learning-curves} shows the learning curves for Random Forest on both tasks. Key observations:

\begin{itemize}
    \item \textbf{No severe overfitting:} Training and validation scores converge, indicating the model generalises well
    \item \textbf{Potential for improvement:} The curves have not fully plateaued, suggesting additional data could improve performance
    \item \textbf{Interview task learns faster:} The interview task achieves higher validation scores with the same amount of training data
\end{itemize}

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.48\textwidth]{figures/advanced/reading_learning_curve.png}
    % \includegraphics[width=0.48\textwidth]{figures/advanced/interview_learning_curve.png}
    \caption{Learning curves showing training and cross-validation accuracy as a function of training set size: (a) Reading task, (b) Interview task}
    \label{fig:learning-curves}
\end{figure}

\section{Visualisations}

Figure \ref{fig:feature-importance} shows the feature importance distributions for both tasks side by side.

\begin{figure}[h]
    \centering
    % \includegraphics[width=\textwidth]{figures/advanced/feature_importance_comparison.png}
    \caption{Top 10 features by Gini importance: Reading task (left) vs Interview task (right)}
    \label{fig:feature-importance}
\end{figure}

Figure \ref{fig:accuracy-comparison} presents the accuracy comparison across tasks and algorithms.

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.7\textwidth]{figures/advanced/accuracy_comparison.png}
    \caption{Classification accuracy comparison by task and algorithm}
    \label{fig:accuracy-comparison}
\end{figure}

The visualisations reveal:
\begin{itemize}
    \item Reading task importance is more evenly distributed across features
    \item Interview task has a steeper importance gradient, with the top feature (spectral flux variability) substantially more important than subsequent features
    \item The accuracy gap between tasks is consistent across both classifiers
\end{itemize}

\section{Summary of Findings}

\begin{enumerate}
    \item \textbf{Interview speech is significantly more informative:} 87.1\% accuracy vs 72.3\% for reading (p = 0.0055)
    
    \item \textbf{Different features matter for each task:}
    \begin{itemize}
        \item Reading: Spectral slope, MFCC, rhythm
        \item Interview: Spectral dynamics, pausing, voice quality variability
    \end{itemize}
    
    \item \textbf{Variability measures are key for interview speech:} The most predictive interview features are \textit{standard deviations}, not means—consistent with ``flat'' depressed speech
    
    \item \textbf{Pausing behaviour is highly informative:} Unvoiced segment features rank prominently for interview speech, reflecting psychomotor retardation
    
    \item \textbf{Confusion matrices show balanced errors for interview:} Both false positives and false negatives are low
    
    \item \textbf{Gender bias in misclassification:} Female speakers are more often misclassified, warranting further investigation
    
    \item \textbf{No overfitting detected:} Learning curves show good generalisation with potential for improvement with more data
\end{enumerate}

These findings directly address the research question and provide interpretable insights into how depression manifests in speech.
