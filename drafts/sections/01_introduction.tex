\chapter{Introduction}

\section{Motivation}

Depression affects over 280 million people globally, making it one of the leading causes of disability worldwide~\cite{WHO2024}. In the United Kingdom alone, approximately one in six adults experiences depression or anxiety in any given week, with an estimated economic burden of £105 billion annually~\cite{McManus2016, OECD2018}.

Despite its prevalence, depression remains significantly underdiagnosed and undertreated. Current diagnostic methods rely primarily on clinical interviews and self-report questionnaires such as the Patient Health Questionnaire (PHQ-9)~\cite{Kroenke2001}. These approaches face several critical limitations:

\begin{itemize}
    \item \textbf{Subjectivity:} Diagnostic agreement between clinicians can be inconsistent, with inter-rater reliability as low as 0.28 kappa for certain depression subtypes~\cite{Regier2013}.
    
    \item \textbf{Self-report bias:} Patients may underreport symptoms due to stigma, lack of insight, or difficulty articulating their experiences.
    
    \item \textbf{Resource constraints:} Clinical assessments require trained mental health professionals, limiting scalability and accessibility.
    
    \item \textbf{Access barriers:} Many individuals, particularly in underserved communities, lack access to specialist care.
\end{itemize}

These limitations have motivated research into objective, scalable biomarkers for depression. Among the most promising candidates is \textit{speech}. Depression affects cognitive processes that directly influence speech production—changes that are often involuntary and difficult to consciously mask~\cite{Cummins2015}. Recording and analysing speech is non-invasive, inexpensive, and can be performed remotely, making it an attractive option for large-scale screening.

Recent advances in machine learning have enabled automatic detection of depression from speech with accuracy comparable to general practitioners~\cite{Tao2024}. However, most research has focused on maximising classification accuracy, treating models as ``black boxes.'' This raises a critical question: \textit{which aspects of speech actually indicate depression?}

Understanding which acoustic features predict depression is essential for:
\begin{enumerate}
    \item \textbf{Clinical utility:} Clinicians cannot act on ``83\% accuracy''—they need interpretable markers.
    \item \textbf{Scientific understanding:} Identifying robust biomarkers advances our understanding of how depression manifests in behaviour.
    \item \textbf{System design:} Knowing which features matter informs what data to collect and how to deploy screening tools.
\end{enumerate}

This dissertation addresses this gap by systematically analysing which acoustic features are most predictive of depression, and how their importance differs between controlled (read) and naturalistic (spontaneous) speech.


\section{Aims}

This project aims to:

\begin{enumerate}
    \item \textbf{Identify predictive features:} Determine which acoustic and prosodic features are most strongly associated with depression, using interpretable machine learning techniques.
    
    \item \textbf{Compare speech tasks:} Analyse whether the same features predict depression in read speech (controlled phonetic content) versus spontaneous speech (natural conversation), and which task yields more reliable detection.
    
    \item \textbf{Provide interpretable analysis:} Move beyond accuracy metrics to explain \textit{why} models predict depression, using feature importance methods such as SHAP values.
\end{enumerate}

The research question guiding this work is:

\begin{quote}
\textit{Which acoustic features of speech are most predictive of depression, and how do they differ between read and spontaneous speech?}
\end{quote}


\section{Outline}

This dissertation is structured as follows:

\begin{description}
    \item[Chapter 2: Background] Reviews the relationship between depression and speech production, formally defines acoustic features used in analysis, surveys machine learning approaches to depression detection, and discusses related work including the ANDROIDS corpus.
    
    \item[Chapter 3: Design] Describes the experimental methodology, including data selection, feature extraction pipeline, classification approach, and feature importance analysis techniques.
    
    \item[Chapter 4: Implementation] Details the technical implementation, including tools used, data processing pipeline, and experimental setup.
    
    \item[Chapter 5: Evaluation] Presents classification results, feature importance rankings, and comparison between read and spontaneous speech tasks.
    
    \item[Chapter 6: Discussion] Critically analyses findings, discusses limitations, compares results with existing literature, and considers clinical implications.
    
    \item[Chapter 7: Conclusion] Summarises contributions and suggests directions for future work.
\end{description}
