\chapter{Methodology}

This chapter details the experimental methodology employed in this study. It covers the research approach, data selection, feature extraction process, classification methods, and evaluation strategy.

\section{Research Approach}

This study adopts an empirical, quantitative approach to investigate which acoustic features of speech are most predictive of depression, with a particular focus on comparing read versus spontaneous speech modalities. The experimental design follows a supervised machine learning paradigm:

\begin{enumerate}
    \item Extract standardised acoustic features from speech recordings
    \item Train classification models to distinguish depressed from healthy individuals
    \item Analyse feature importance to identify the most predictive acoustic markers
    \item Compare results across speech tasks (reading versus interview)
\end{enumerate}

This approach was chosen over deep learning methods specifically because the research question centres on \textit{interpretability}—understanding which features contribute to depression detection—rather than maximising classification accuracy alone. While neural network approaches have achieved higher accuracy in some studies \cite{cummins2015review}, their ``black box'' nature makes clinical interpretation difficult.

\section{Dataset Selection}

\subsection{The ANDROIDS Corpus}

The ANDROIDS (ANDRoid corpus fOr Identification of Depression and Suicide risk) corpus \cite{dinkel2019androids} was selected for this study. It contains speech recordings from 118 Italian speakers, comprising both individuals with clinical depression diagnoses and healthy controls.

\subsubsection{Corpus Characteristics}

\begin{table}[h]
\centering
\caption{ANDROIDS corpus composition}
\label{tab:corpus-composition}
\begin{tabular}{lcccc}
\hline
\textbf{Group} & \textbf{Reading} & \textbf{Interview} & \textbf{Total} \\
\hline
Healthy Controls (HC) & 54 & 52 & 106 \\
Patients (PT) & 58 & 64 & 122 \\
\textbf{Total} & 112 & 116 & 228 \\
\hline
\end{tabular}
\end{table}

Key advantages of this corpus for the current study:

\begin{itemize}
    \item \textbf{Dual speech tasks:} Includes both reading and interview recordings from the same participants, enabling direct comparison of speech modalities
    \item \textbf{Clinical diagnoses:} Depression labels are based on psychiatric assessment, not self-report questionnaires
    \item \textbf{Public availability:} Enables reproducibility of results
    \item \textbf{Controlled recording conditions:} Minimises acoustic variation from environmental factors
\end{itemize}

\subsubsection{Speech Tasks}

The corpus contains two distinct speech tasks:

\paragraph{Reading Task:} Participants read a standardised Italian text passage aloud. This provides controlled linguistic content, allowing acoustic analysis independent of spontaneous language production processes.

\paragraph{Interview Task:} Participants engaged in semi-structured interviews covering topics such as daily routines, emotional experiences, and future plans. This elicits naturalistic speech with variable linguistic content.

The inclusion of both tasks is central to the research question, as the cognitive demands of reading versus spontaneous speech differ substantially, and these may interact differently with depression-related speech patterns.

\subsection{Ethical Considerations}

The ANDROIDS corpus is publicly available for research purposes. All recordings were collected with informed consent, and data are anonymised. No additional ethics approval was required for this secondary analysis of existing data.

\section{Feature Extraction}

\subsection{The eGeMAPS Feature Set}

Acoustic features were extracted using the extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS) \cite{eyben2016geneva}, a standardised feature set designed specifically for affective computing and clinical speech analysis. The eGeMAPS set was chosen for several reasons:

\begin{enumerate}
    \item \textbf{Standardisation:} Enables comparison with published literature using the same features
    \item \textbf{Interpretability:} Features have clear acoustic and physiological interpretations
    \item \textbf{Comprehensiveness:} Covers prosody, voice quality, spectral characteristics, and temporal dynamics
    \item \textbf{Manageable dimensionality:} 88 features provide rich representation without excessive complexity
\end{enumerate}

\subsection{Feature Categories}

The 88 eGeMAPS features span several acoustic domains:

\begin{table}[h]
\centering
\caption{eGeMAPS feature categories}
\label{tab:feature-categories}
\begin{tabular}{lp{7cm}}
\hline
\textbf{Category} & \textbf{Features} \\
\hline
Frequency (F0) & Pitch mean, standard deviation, percentiles, slopes \\
Energy/Loudness & Mean loudness, peak rate, slopes, percentiles \\
Spectral & MFCCs (1-4), spectral flux, formant frequencies, bandwidth \\
Voice Quality & Jitter, shimmer, Hammarberg index, alpha ratio \\
Temporal & Voiced/unvoiced segment duration, speech rate \\
\hline
\end{tabular}
\end{table}

\subsection{Extraction Process}

Feature extraction was performed using the openSMILE toolkit \cite{eyben2010opensmile} via its Python bindings. For each audio file, the extraction pipeline:

\begin{enumerate}
    \item Loaded the WAV file (16-bit PCM format)
    \item Applied the eGeMAPS configuration with functional statistics
    \item Generated a single 88-dimensional feature vector per recording
    \item Stored features alongside metadata (speaker ID, condition, task)
\end{enumerate}

The ``functionals'' level was used, computing statistical summaries (mean, standard deviation, percentiles) over frame-level features across the entire recording. This produces a fixed-length representation regardless of recording duration.

\section{Classification Methods}

Two classification algorithms were employed: Support Vector Machines (SVM) and Random Forest. Both are well-established methods for speech-based depression detection with complementary strengths.

\subsection{Support Vector Machine}

SVMs find the hyperplane that maximally separates classes in feature space. A radial basis function (RBF) kernel was used to capture nonlinear relationships:

\begin{equation}
    K(x_i, x_j) = \exp\left(-\gamma \|x_i - x_j\|^2\right)
\end{equation}

Feature standardisation (zero mean, unit variance) was applied prior to SVM training, as the RBF kernel is sensitive to feature scales.

\textbf{Hyperparameters:}
\begin{itemize}
    \item Kernel: RBF
    \item Regularisation (C): 1.0
    \item Gamma: Scale (1 / (n\_features $\times$ variance))
\end{itemize}

\subsection{Random Forest}

Random Forest constructs an ensemble of decision trees, each trained on a bootstrap sample with random feature subsets. The ensemble averages predictions across trees, reducing overfitting and providing built-in feature importance estimates.

\textbf{Hyperparameters:}
\begin{itemize}
    \item Number of trees: 100
    \item Maximum depth: 10
    \item Split criterion: Gini impurity
\end{itemize}

The depth limit was imposed to prevent overfitting on the relatively small dataset.

\section{Evaluation Strategy}

\subsection{Cross-Validation}

All results are reported using 5-fold stratified cross-validation. Stratification ensures each fold maintains the same class distribution as the full dataset, important given the mild class imbalance.

For each fold:
\begin{enumerate}
    \item Train on 80\% of data
    \item Test on held-out 20\%
    \item Record accuracy and F1 score
\end{enumerate}

Final metrics are the mean and standard deviation across folds.

\subsection{Evaluation Metrics}

\paragraph{Accuracy:} Proportion of correctly classified samples:
\begin{equation}
    \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}

\paragraph{F1 Score:} Harmonic mean of precision and recall, providing balanced evaluation under class imbalance:
\begin{equation}
    F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}

\subsection{Feature Importance Analysis}

To address the research question of which features are most predictive, two complementary importance measures were computed:

\paragraph{Gini Importance:} Measures the total decrease in node impurity (Gini index) attributable to each feature across all trees in the Random Forest. While computationally efficient, Gini importance can be biased toward high-cardinality features.

\paragraph{Permutation Importance:} Measures the decrease in model accuracy when feature values are randomly shuffled. This provides a more reliable estimate of true predictive value:

\begin{equation}
    I_{\text{perm}}(f) = \frac{1}{K} \sum_{k=1}^{K} \left[ \text{Acc}_{\text{original}} - \text{Acc}_{\text{shuffled}}^{(k)} \right]
\end{equation}

where $K=10$ permutations were used per feature.

\section{Reproducibility}

All code, feature files, and analysis scripts are available in the project repository. The complete analysis pipeline can be reproduced by:

\begin{enumerate}
    \item Obtaining the ANDROIDS corpus from the original authors
    \item Running the feature extraction script (\texttt{extract\_features.py})
    \item Running the analysis script (\texttt{run\_analysis.py})
\end{enumerate}

Random seeds were fixed for all stochastic processes to ensure reproducibility.

\section{Summary}

This methodology enables systematic investigation of the research question through:

\begin{itemize}
    \item A carefully selected corpus with both speech modalities
    \item Standardised, interpretable acoustic features (eGeMAPS)
    \item Robust classification with established algorithms
    \item Feature importance analysis for clinical interpretability
    \item Rigorous cross-validation for reliable performance estimates
\end{itemize}

The following chapter details the implementation of this methodology, including technical specifications and code organisation.
